{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binnary clasification using Transformer. An 'Edible Mushroom Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded this dataset from kaggle, just search the title in the web and there will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cap-diameter     54035 non-null  int64  \n",
      " 1   cap-shape        54035 non-null  int64  \n",
      " 2   gill-attachment  54035 non-null  int64  \n",
      " 3   gill-color       54035 non-null  int64  \n",
      " 4   stem-height      54035 non-null  float64\n",
      " 5   stem-width       54035 non-null  int64  \n",
      " 6   stem-color       54035 non-null  int64  \n",
      " 7   season           54035 non-null  float64\n",
      " 8   class            54035 non-null  int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 3.7 MB\n",
      "None\n",
      "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
      "0          1372          2                2          10     3.807467   \n",
      "1          1461          2                2          10     3.807467   \n",
      "2          1371          2                2          10     3.612496   \n",
      "3          1261          6                2          10     3.787572   \n",
      "4          1305          6                2          10     3.711971   \n",
      "\n",
      "   stem-width  stem-color    season  class  \n",
      "0        1545          11  1.804273      1  \n",
      "1        1557          11  1.804273      1  \n",
      "2        1566          11  1.804273      1  \n",
      "3        1566          11  1.804273      1  \n",
      "4        1464          11  0.943195      1  \n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = pd.read_csv('mushroom_cleaned.csv')\n",
    "print(dataset.info())\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the categorical and continous columns:\n",
    "- *Categorical* --> Those who has an int64 dtype\n",
    "- *Continous* --> Those who has a float64 dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['cap-diameter', 'cap-shape', 'gill-attachment', 'gill-color', 'stem-width', 'stem-color' ]\n",
    "continous_cols = ['stem-height', 'season']\n",
    "label_col = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply a categorical encoder to categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols: \n",
    "    le = LabelEncoder()\n",
    "    dataset[col] = le.fit_transform(dataset[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54035, 8), (54035,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We split the dataset into 'data' and 'labels'\n",
    "X = dataset.drop(label_col, axis=1)\n",
    "y = dataset[label_col]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43228, 8), (10807, 8), (43228,), (10807,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43228, 6), (43228, 2), (10807, 6), (10807, 2))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate categotical and continous features\n",
    "X_train_categ = X_train[categorical_cols].values\n",
    "X_train_cont = X_train[continous_cols].values\n",
    "#\n",
    "X_test_categ = X_test[categorical_cols].values\n",
    "X_test_cont = X_test[continous_cols].values\n",
    "X_train_categ.shape, X_train_cont.shape, X_test_categ.shape, X_test_cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TabTransformer model\n",
    "num_unique_categories = [dataset[col].nunique() for col in categorical_cols]\n",
    "#\n",
    "modelTabTrans = TabTransformer(\n",
    "    categories=num_unique_categories,\n",
    "    num_continuous=len(continous_cols),\n",
    "    dim=32,\n",
    "    dim_out=1,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    attn_dropout=.1,\n",
    "    ff_dropout=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data --> Pytorch tensors\n",
    "X_train_categ_tensor = torch.tensor(X_train_categ, dtype=torch.long)\n",
    "X_train_cont_tensor = torch.tensor(X_train_cont, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "#\n",
    "# optimizer and loss function definition\n",
    "optimizer = torch.optim.Adam(modelTabTrans.parameters(), lr=.001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6910781264305115\n",
      "Epoch: 1, Loss: 0.6533674001693726\n",
      "Epoch: 2, Loss: 0.6340625882148743\n",
      "Epoch: 3, Loss: 0.5992587208747864\n",
      "Epoch: 4, Loss: 0.5830015540122986\n",
      "Epoch: 5, Loss: 0.5523414015769958\n",
      "Epoch: 6, Loss: 0.5312123894691467\n",
      "Epoch: 7, Loss: 0.5063426494598389\n",
      "Epoch: 8, Loss: 0.4847387671470642\n",
      "Epoch: 9, Loss: 0.46398094296455383\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "modelTabTrans.train()\n",
    "for epoch in range(10): # 10 epoch training\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = modelTabTrans(X_train_categ_tensor, X_train_cont_tensor)\n",
    "    loss = criterion(y_pred.squeeze(), y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.44760382175445557\n",
      "Test Accuracy: 78.3751\n"
     ]
    }
   ],
   "source": [
    "# Evaluation ( test loss  + accuracy )\n",
    "modelTabTrans.eval() \n",
    "with torch.no_grad():\n",
    "    X_test_categ_tensor = torch.tensor(X_test_categ, dtype=torch.long)\n",
    "    X_test_cont_tensor = torch.tensor(X_test_cont, dtype=torch.float)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
    "    test_output = modelTabTrans(X_test_categ_tensor, X_test_cont_tensor)\n",
    "    test_loss = criterion(test_output.squeeze(), y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item()}')\n",
    "    \n",
    "    # Accuracy\n",
    "    test_preds = torch.sigmoid(test_output).squeeze().round()\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), test_preds.numpy())\n",
    "    print(f'Test Accuracy: {accuracy * 100:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
