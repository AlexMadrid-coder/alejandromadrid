{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binnary clasification using Transformer. An 'Edible Mushroom Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded this dataset from kaggle, just search the title in the web and there will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = pd.read_csv('mushroom_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "0          1372          2                2          10     3.807467   \n",
       "1          1461          2                2          10     3.807467   \n",
       "2          1371          2                2          10     3.612496   \n",
       "3          1261          6                2          10     3.787572   \n",
       "4          1305          6                2          10     3.711971   \n",
       "\n",
       "   stem-width  stem-color    season  class  \n",
       "0        1545          11  1.804273      1  \n",
       "1        1557          11  1.804273      1  \n",
       "2        1566          11  1.804273      1  \n",
       "3        1566          11  1.804273      1  \n",
       "4        1464          11  0.943195      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 2 classes to classify:\n",
    "- class 1 --> Non edible Mushroom\n",
    "- class 0 --> Edible Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cap-diameter     54035 non-null  int64  \n",
      " 1   cap-shape        54035 non-null  int64  \n",
      " 2   gill-attachment  54035 non-null  int64  \n",
      " 3   gill-color       54035 non-null  int64  \n",
      " 4   stem-height      54035 non-null  float64\n",
      " 5   stem-width       54035 non-null  int64  \n",
      " 6   stem-color       54035 non-null  int64  \n",
      " 7   season           54035 non-null  float64\n",
      " 8   class            54035 non-null  int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29675, 9), (24360, 9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're going to test if we have a balanced dataset\n",
    "dataset[dataset[\"class\"]==1].shape , dataset[dataset[\"class\"]==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a barely balanced dataset with $29675$ $non$-$edible$ mushrooms and $24360$ $edible$ mushrooms\n",
    "\n",
    "As we can see in the info, we're going to make our columns into categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['cap-diameter','cap-shape', 'gill-attachment', 'gill-color', 'stem-height', 'stem-width', 'stem-color', 'season' ]\n",
    "\n",
    "# Label encoding\n",
    "labelEncoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    dataset[col + '_encoded'] = labelEncoder.fit_transform(dataset[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter_encoded</th>\n",
       "      <th>cap-shape_encoded</th>\n",
       "      <th>gill-attachment_encoded</th>\n",
       "      <th>gill-color_encoded</th>\n",
       "      <th>stem-height_encoded</th>\n",
       "      <th>stem-width_encoded</th>\n",
       "      <th>stem-color_encoded</th>\n",
       "      <th>season_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1447</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1447</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1399</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1442</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1</td>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1424</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "0          1372          2                2          10     3.807467   \n",
       "1          1461          2                2          10     3.807467   \n",
       "2          1371          2                2          10     3.612496   \n",
       "3          1261          6                2          10     3.787572   \n",
       "4          1305          6                2          10     3.711971   \n",
       "\n",
       "   stem-width  stem-color    season  class  cap-diameter_encoded  \\\n",
       "0        1545          11  1.804273      1                  1372   \n",
       "1        1557          11  1.804273      1                  1461   \n",
       "2        1566          11  1.804273      1                  1371   \n",
       "3        1566          11  1.804273      1                  1261   \n",
       "4        1464          11  0.943195      1                  1305   \n",
       "\n",
       "   cap-shape_encoded  gill-attachment_encoded  gill-color_encoded  \\\n",
       "0                  2                        2                  10   \n",
       "1                  2                        2                  10   \n",
       "2                  2                        2                  10   \n",
       "3                  6                        2                  10   \n",
       "4                  6                        2                  10   \n",
       "\n",
       "   stem-height_encoded  stem-width_encoded  stem-color_encoded  season_encoded  \n",
       "0                 1447                1545                  11               3  \n",
       "1                 1447                1557                  11               3  \n",
       "2                 1399                1566                  11               3  \n",
       "3                 1442                1566                  11               3  \n",
       "4                 1424                1464                  11               2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Columns: 6847 entries, cap-diameter_1 to season_1.804272708628173\n",
      "dtypes: float64(6847)\n",
      "memory usage: 2.8 GB\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "onehotEncoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encodedFeatures = pd.DataFrame(onehotEncoder.fit_transform(dataset[categorical_columns]), \n",
    "                                columns=onehotEncoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "encodedFeatures.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have encoded the features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cap-diameter_1', 'cap-diameter_2', 'cap-diameter_3', ...,\n",
       "       'season_0.8884502877862838', 'season_0.9431945538974952',\n",
       "       'season_1.804272708628173'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureNames = onehotEncoder.get_feature_names_out(categorical_columns)\n",
    "featureNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Columns: 6847 entries, cap-diameter_1 to season_1.804272708628173\n",
      "dtypes: float64(6847)\n",
      "memory usage: 2.8 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((54035, 6847),\n",
       " None,\n",
       "    cap-diameter_1  cap-diameter_2  cap-diameter_3  cap-diameter_4  \\\n",
       " 0             0.0             0.0             0.0             0.0   \n",
       " 1             0.0             0.0             0.0             0.0   \n",
       " 2             0.0             0.0             0.0             0.0   \n",
       " 3             0.0             0.0             0.0             0.0   \n",
       " 4             0.0             0.0             0.0             0.0   \n",
       " \n",
       "    cap-diameter_5  cap-diameter_6  cap-diameter_7  cap-diameter_8  \\\n",
       " 0             0.0             0.0             0.0             0.0   \n",
       " 1             0.0             0.0             0.0             0.0   \n",
       " 2             0.0             0.0             0.0             0.0   \n",
       " 3             0.0             0.0             0.0             0.0   \n",
       " 4             0.0             0.0             0.0             0.0   \n",
       " \n",
       "    cap-diameter_9  cap-diameter_10  ...  stem-color_6  stem-color_7  \\\n",
       " 0             0.0              0.0  ...           0.0           0.0   \n",
       " 1             0.0              0.0  ...           0.0           0.0   \n",
       " 2             0.0              0.0  ...           0.0           0.0   \n",
       " 3             0.0              0.0  ...           0.0           0.0   \n",
       " 4             0.0              0.0  ...           0.0           0.0   \n",
       " \n",
       "    stem-color_8  stem-color_9  stem-color_10  stem-color_11  stem-color_12  \\\n",
       " 0           0.0           0.0            0.0            1.0            0.0   \n",
       " 1           0.0           0.0            0.0            1.0            0.0   \n",
       " 2           0.0           0.0            0.0            1.0            0.0   \n",
       " 3           0.0           0.0            0.0            1.0            0.0   \n",
       " 4           0.0           0.0            0.0            1.0            0.0   \n",
       " \n",
       "    season_0.8884502877862838  season_0.9431945538974952  \\\n",
       " 0                        0.0                        0.0   \n",
       " 1                        0.0                        0.0   \n",
       " 2                        0.0                        0.0   \n",
       " 3                        0.0                        0.0   \n",
       " 4                        0.0                        1.0   \n",
       " \n",
       "    season_1.804272708628173  \n",
       " 0                       1.0  \n",
       " 1                       1.0  \n",
       " 2                       1.0  \n",
       " 3                       1.0  \n",
       " 4                       0.0  \n",
       " \n",
       " [5 rows x 6847 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedDataset = pd.DataFrame(encodedFeatures, columns=featureNames)\n",
    "encodedDataset.shape, encodedDataset.info(), encodedDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Columns: 6864 entries, cap-diameter to season_1.804272708628173\n",
      "dtypes: float64(6849), int64(15)\n",
      "memory usage: 2.8 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((54035, 6864),\n",
       " None,\n",
       "    cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       " 0          1372          2                2          10     3.807467   \n",
       " 1          1461          2                2          10     3.807467   \n",
       " 2          1371          2                2          10     3.612496   \n",
       " 3          1261          6                2          10     3.787572   \n",
       " 4          1305          6                2          10     3.711971   \n",
       " \n",
       "    stem-width  stem-color    season  class  cap-diameter_encoded  ...  \\\n",
       " 0        1545          11  1.804273      1                  1372  ...   \n",
       " 1        1557          11  1.804273      1                  1461  ...   \n",
       " 2        1566          11  1.804273      1                  1371  ...   \n",
       " 3        1566          11  1.804273      1                  1261  ...   \n",
       " 4        1464          11  0.943195      1                  1305  ...   \n",
       " \n",
       "    stem-color_6  stem-color_7  stem-color_8  stem-color_9  stem-color_10  \\\n",
       " 0           0.0           0.0           0.0           0.0            0.0   \n",
       " 1           0.0           0.0           0.0           0.0            0.0   \n",
       " 2           0.0           0.0           0.0           0.0            0.0   \n",
       " 3           0.0           0.0           0.0           0.0            0.0   \n",
       " 4           0.0           0.0           0.0           0.0            0.0   \n",
       " \n",
       "    stem-color_11  stem-color_12  season_0.8884502877862838  \\\n",
       " 0            1.0            0.0                        0.0   \n",
       " 1            1.0            0.0                        0.0   \n",
       " 2            1.0            0.0                        0.0   \n",
       " 3            1.0            0.0                        0.0   \n",
       " 4            1.0            0.0                        0.0   \n",
       " \n",
       "    season_0.9431945538974952  season_1.804272708628173  \n",
       " 0                        0.0                       1.0  \n",
       " 1                        0.0                       1.0  \n",
       " 2                        0.0                       1.0  \n",
       " 3                        0.0                       1.0  \n",
       " 4                        1.0                       0.0  \n",
       " \n",
       " [5 rows x 6864 columns])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We concatenate the original dataset with the new one\n",
    "encodedDataset = pd.concat([dataset, encodedFeatures], axis=1)\n",
    "encodedDataset.shape, encodedDataset.info(), encodedDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Columns: 6856 entries, class to season_1.804272708628173\n",
      "dtypes: float64(6847), int64(9)\n",
      "memory usage: 2.8 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((54035, 6856),\n",
       " None,\n",
       "    class  cap-diameter_encoded  cap-shape_encoded  gill-attachment_encoded  \\\n",
       " 0      1                  1372                  2                        2   \n",
       " 1      1                  1461                  2                        2   \n",
       " 2      1                  1371                  2                        2   \n",
       " 3      1                  1261                  6                        2   \n",
       " 4      1                  1305                  6                        2   \n",
       " \n",
       "    gill-color_encoded  stem-height_encoded  stem-width_encoded  \\\n",
       " 0                  10                 1447                1545   \n",
       " 1                  10                 1447                1557   \n",
       " 2                  10                 1399                1566   \n",
       " 3                  10                 1442                1566   \n",
       " 4                  10                 1424                1464   \n",
       " \n",
       "    stem-color_encoded  season_encoded  cap-diameter_1  ...  stem-color_6  \\\n",
       " 0                  11               3             0.0  ...           0.0   \n",
       " 1                  11               3             0.0  ...           0.0   \n",
       " 2                  11               3             0.0  ...           0.0   \n",
       " 3                  11               3             0.0  ...           0.0   \n",
       " 4                  11               2             0.0  ...           0.0   \n",
       " \n",
       "    stem-color_7  stem-color_8  stem-color_9  stem-color_10  stem-color_11  \\\n",
       " 0           0.0           0.0           0.0            0.0            1.0   \n",
       " 1           0.0           0.0           0.0            0.0            1.0   \n",
       " 2           0.0           0.0           0.0            0.0            1.0   \n",
       " 3           0.0           0.0           0.0            0.0            1.0   \n",
       " 4           0.0           0.0           0.0            0.0            1.0   \n",
       " \n",
       "    stem-color_12  season_0.8884502877862838  season_0.9431945538974952  \\\n",
       " 0            0.0                        0.0                        0.0   \n",
       " 1            0.0                        0.0                        0.0   \n",
       " 2            0.0                        0.0                        0.0   \n",
       " 3            0.0                        0.0                        0.0   \n",
       " 4            0.0                        0.0                        1.0   \n",
       " \n",
       "    season_1.804272708628173  \n",
       " 0                       1.0  \n",
       " 1                       1.0  \n",
       " 2                       1.0  \n",
       " 3                       1.0  \n",
       " 4                       0.0  \n",
       " \n",
       " [5 rows x 6856 columns])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedDataset.drop(categorical_columns, axis=1, inplace=True)\n",
    "encodedDataset.shape, encodedDataset.info(), encodedDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have our pre-processed dataset so we can continue splitting into traning and testing and try those wit different methods and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encodedDataset.drop('class', axis=1)\n",
    "Y = encodedDataset['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43228, 6855), (5403, 6855), (5404, 6855), (43228,), (5403,), (5404,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, train_size=.8, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size=0.5)\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "trainDataset = trainDataset.shuffle(buffer_size=len(X_train)).batch(32)\n",
    "#\n",
    "valDataset = tf.data.Dataset.from_tensor_slices((X_val.values, y_val.values))\n",
    "valDataset = valDataset.shuffle(buffer_size=len(X_val)).batch(32)\n",
    "# \n",
    "testDataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n",
    "testDataset = testDataset.shuffle(buffer_size=len(X_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6855"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [X_train[col].nunique() for col in X_train.columns]\n",
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1821,\n",
       " 7,\n",
       " 7,\n",
       " 12,\n",
       " 1442,\n",
       " 3452,\n",
       " 13,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "model = TabTransformer(\n",
    "    categories=categories,\n",
    "    num_continuous=(X_train.shape[1] - len(categorical_columns)),\n",
    "    dim=32,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.1\n",
    ")\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binnary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Train model\n",
    "history = model.fit(trainDataset, valDataset, epochs=10)\n",
    "\n",
    "# Evalue the model\n",
    "test_loss, test_accuracy = model.evaluate(testDataset)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
