{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP True-Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vamos a realizar un clasificador de NLP usando AIDE sobre noticias verdaderas y falsas.\n",
    "\n",
    "Este dataset lo podemos encontrar en kaggle --> <a href=\"https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\"> fake-and-real-news-dataset</a>\n",
    "\n",
    "\n",
    "El objetivo de este es ver como se desempeña la herramienta en un problema de clasificación de NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from  datetime import datetime\n",
    "import AIDE as aide\n",
    "ini_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Data/\" \n",
    "goal = \"Build a classifier for fake and true news.\" \n",
    "eval=\"RMSLE, confusion matrix and ROC Curve\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar el modelo **gpt-4-turbo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp = aide.Experiment(\n",
    "    data_dir=data_dir,\n",
    "    goal=goal,\n",
    "    eval=eval\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro/Documents/Repositorios/alejandromadrid/.python-aide-venv/lib/python3.10/site-packages/AIDE/utils/tree_export.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  layout = (layout - layout.min(axis=0)) / (layout.max(axis=0) - layout.min(axis=0))\n"
     ]
    }
   ],
   "source": [
    "best_solution = exp.run(steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 1:48:44.603162\n"
     ]
    }
   ],
   "source": [
    "print(f'Tiempo de ejecución: {datetime.now()-ini_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código ha costado : <label style=\"color:red\">$0.45</label>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La validación es de: 0.9996860860658481\n"
     ]
    }
   ],
   "source": [
    "print(f'La validación es de: {best_solution.valid_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de una larga ejecución de casi 2 horas y poco más de $0.45 ha acabado de crearse, ejecutarse y optimizarse el algoritmo que vamos a probar ahora mismo. \n",
    "\n",
    "Tiene buena pinta y una validación de la solución dentro del propio AIDE casi perfecta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El código es: import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import mean_squared_log_error, confusion_matrix, roc_curve, auc\n",
      "import numpy as np\n",
      "\n",
      "# Load data\n",
      "fake_news = pd.read_csv(\"./input/Fake.csv\")\n",
      "true_news = pd.read_csv(\"./input/True.csv\")\n",
      "\n",
      "# Label the data\n",
      "fake_news[\"label\"] = 0\n",
      "true_news[\"label\"] = 1\n",
      "\n",
      "# Combine the datasets\n",
      "data = pd.concat([fake_news, true_news], ignore_index=True)\n",
      "\n",
      "# Select features and labels\n",
      "X = data[\"text\"]\n",
      "y = data[\"label\"]\n",
      "\n",
      "# Split the data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    X, y, test_size=0.2, random_state=42\n",
      ")\n",
      "\n",
      "# Vectorize the text data\n",
      "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
      "X_train_tfidf = tfidf.fit_transform(X_train)\n",
      "X_test_tfidf = tfidf.transform(X_test)\n",
      "\n",
      "# Initialize and train the Random Forest classifier\n",
      "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "rf_classifier.fit(X_train_tfidf, y_train)\n",
      "\n",
      "# Predict on the test set\n",
      "y_pred = rf_classifier.predict(X_test_tfidf)\n",
      "y_pred_proba = rf_classifier.predict_proba(X_test_tfidf)[:, 1]\n",
      "\n",
      "# Calculate RMSLE\n",
      "rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred_proba))\n",
      "\n",
      "# Calculate confusion matrix\n",
      "conf_matrix = confusion_matrix(y_test, y_pred)\n",
      "\n",
      "# Calculate ROC AUC\n",
      "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "# Print metrics\n",
      "print(\"RMSLE:\", rmsle)\n",
      "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
      "print(\"ROC AUC:\", roc_auc)\n",
      "\n",
      "# Save predictions for evaluation\n",
      "predictions = pd.DataFrame({\"True_Label\": y_test, \"Predicted_Label\": y_pred})\n",
      "predictions.to_csv(\"./working/submission.csv\", index=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'El código es: {best_solution.code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ahora probamos el código proporcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 0.08802924041547952\n",
      "Confusion Matrix:\n",
      " [[4719   14]\n",
      " [  11 4236]]\n",
      "ROC AUC: 0.9996860860658481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_log_error, confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "fake_news = pd.read_csv(\"./Data/Fake.csv\")\n",
    "true_news = pd.read_csv(\"./Data/True.csv\")\n",
    "\n",
    "# Label the data\n",
    "fake_news[\"label\"] = 0\n",
    "true_news[\"label\"] = 1\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([fake_news, true_news], ignore_index=True)\n",
    "\n",
    "# Select features and labels\n",
    "X = data[\"text\"]\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize the text data\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test_tfidf)\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Calculate RMSLE\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred_proba))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Print metrics\n",
    "print(\"RMSLE:\", rmsle)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Save predictions for evaluation\n",
    "predictions = pd.DataFrame({\"True_Label\": y_test, \"Predicted_Label\": y_pred})\n",
    "predictions.to_csv(\"./Data/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, AIDE ha sido capaz de obtener una puntuación casi perfecta en esta clasificación, ha demostrado ser más que eficaz en este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-aide-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
