{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure Classification using PandasAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset est谩 sacado de kaggle en este enlace, <a href=\"https://www.kaggle.com/datasets/aadarshvelu/heart-failure-prediction-clinical-records/data\">Heart Failure Prediction - Clinical Records  </a>\n",
    "\n",
    "Este dataset tiene datos de los pacientes y nos indica si estos sufriesen un ataque al coraz贸n si sobrevivir铆an o no a una operaci贸n as铆 como al translado urgente al hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasai\n",
    "import os \n",
    "from dotenv import dotenv_values\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment key\n",
    "keys = dotenv_values(\"../.env-token\")\n",
    "os.environ[\"PANDASAI_API_KEY\"] = keys[\"PANDASAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       5000 non-null   float64\n",
      " 1   anaemia                   5000 non-null   int64  \n",
      " 2   creatinine_phosphokinase  5000 non-null   int64  \n",
      " 3   diabetes                  5000 non-null   int64  \n",
      " 4   ejection_fraction         5000 non-null   int64  \n",
      " 5   high_blood_pressure       5000 non-null   int64  \n",
      " 6   platelets                 5000 non-null   float64\n",
      " 7   serum_creatinine          5000 non-null   float64\n",
      " 8   serum_sodium              5000 non-null   int64  \n",
      " 9   sex                       5000 non-null   int64  \n",
      " 10  smoking                   5000 non-null   int64  \n",
      " 11  time                      5000 non-null   int64  \n",
      " 12  DEATH_EVENT               5000 non-null   int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 507.9 KB\n"
     ]
    }
   ],
   "source": [
    "init_time = datetime\n",
    "file_dir=\"Data/heart_failure_clinical_records.csv\"\n",
    "file = pd.read_csv(file_dir)\n",
    "file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como descripci贸n simplemente vamos a decirle el n煤mero de columnas y cu谩l es la que tenemos como 'target' para la clasificaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqu铆 pondemos una peque帽a descripci贸n del dataset\n",
    "DESCRIPTION = \"\"\"\n",
    "The dataset has 13 columns, the target columns is DEATH_EVENT with 2 values\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pasarle como configuraci贸n que use el modelo gpt-4-turbo, al igual que AIDE para tenerlos en igualdad de condiciones en lo que al LLM respecta ya que este no realiza varias iteraciones sobre varios programas buscando cu谩l es el m谩s 贸ptimo. Este sacar谩 un c贸digo, lo ejecutar谩 y nosotros sacaremos el c贸digo. \n",
    "\n",
    "Todas las consultas e input+output prompts los podemos encontrar en el fichero pandasai.log. No es recomendable entrar a buscar una consulta simple ya que cada vez que hacemos una llamada a PandasAI este copia input y output en el fichero pandasai.log por lo que es un fichero de tama帽o considerable con consultas no parecidas sobre las que pandasai tiene constancia para aumentar la velocidad en las siguientes consultas si estas son monotema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(model=\"gpt-4o\") #Este es el modelo de OpenAI que vamos a utilizar\n",
    "smartDataFrame = SmartDataframe(file, description=DESCRIPTION, config={\"llm\":llm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos el chat y que nos proporcione una soluci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       698\n",
      "           1       0.99      0.99      0.99       302\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[694   4]\n",
      " [  3 299]]\n"
     ]
    }
   ],
   "source": [
    "response = smartDataFrame.chat(\"Make a classifier for this dataset that predicts if a patient will survive a heart failure? (DEATH_EVENT=1 --> True class)\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Coste de ejecuci贸nn --> <label style=\"color:red\">Parece que no me ha costado nada</label> < de $.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el c贸digo y lo ejecutamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df = dfs[0]\n",
      "X = df.drop('DEATH_EVENT', axis=1)\n",
      "y = df['DEATH_EVENT']\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(X_train, y_train)\n",
      "y_pred = clf.predict(X_test)\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "report = classification_report(y_test, y_pred)\n",
      "conf_matrix = confusion_matrix(y_test, y_pred)\n",
      "result = {'type': 'string', 'value': f\"\"\"Accuracy: {accuracy}\n",
      "\n",
      "Classification Report:\n",
      "{report}\n",
      "\n",
      "Confusion Matrix:\n",
      "{conf_matrix}\"\"\"}\n"
     ]
    }
   ],
   "source": [
    "print(smartDataFrame.last_code_executed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver comparando el c贸digo los c贸digo de las celdas pegadas a esta no coinciden del todo ya que PandasAI, a diferencia de otras, no devuelve los imports ni printea el resultado ya que este lo devuelve en forma de un report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       698\n",
      "           1       0.98      0.99      0.99       302\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[692   6]\n",
      " [  2 300]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "df = file\n",
    "X = df.drop('DEATH_EVENT', axis=1)\n",
    "y = df['DEATH_EVENT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "result = {'type': 'string', 'value': f\"\"\"Accuracy: {accuracy}\n",
    "\n",
    "Classification Report:\n",
    "{report}\n",
    "\n",
    "Confusion Matrix:\n",
    "{conf_matrix}\"\"\"}\n",
    "\n",
    "print(accuracy)\n",
    "print(report)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando el reporte de la clasificaci贸n tenemos puntuaciones de accuracy, recall, f1-score y una matriz de confusi贸 casi perfecta por lo que PandasAI ha sido capaz de clasificar perfectamente el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-pandasai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
