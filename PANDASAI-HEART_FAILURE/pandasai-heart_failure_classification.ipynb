{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Failure Classification using PandasAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset está sacado de kaggle en este enlace, <a href=\"https://www.kaggle.com/datasets/aadarshvelu/heart-failure-prediction-clinical-records/data\">Heart Failure Prediction - Clinical Records 🏥 </a>\n",
    "\n",
    "Este dataset tiene datos de los pacientes y nos indica si estos sufriesen un ataque al corazón si sobrevivirían o no a una operación así como al translado urgente al hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasai\n",
    "import os \n",
    "from dotenv import dotenv_values\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment key\n",
    "keys = dotenv_values(\"../.env-token\")\n",
    "os.environ[\"PANDASAI_API_KEY\"] = keys[\"PANDASAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       5000 non-null   float64\n",
      " 1   anaemia                   5000 non-null   int64  \n",
      " 2   creatinine_phosphokinase  5000 non-null   int64  \n",
      " 3   diabetes                  5000 non-null   int64  \n",
      " 4   ejection_fraction         5000 non-null   int64  \n",
      " 5   high_blood_pressure       5000 non-null   int64  \n",
      " 6   platelets                 5000 non-null   float64\n",
      " 7   serum_creatinine          5000 non-null   float64\n",
      " 8   serum_sodium              5000 non-null   int64  \n",
      " 9   sex                       5000 non-null   int64  \n",
      " 10  smoking                   5000 non-null   int64  \n",
      " 11  time                      5000 non-null   int64  \n",
      " 12  DEATH_EVENT               5000 non-null   int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 507.9 KB\n"
     ]
    }
   ],
   "source": [
    "init_time = datetime\n",
    "file_dir=\"Data/heart_failure_clinical_records.csv\"\n",
    "file = pd.read_csv(file_dir)\n",
    "file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como descripción simplemente vamos a decirle el número de columnas y cuál es la que tenemos como 'target' para la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí pondemos una pequeña descripción del dataset\n",
    "DESCRIPTION = \"\"\"\n",
    "The dataset has 13 columns, the target columns is DEATH_EVENT with 2 values\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pasarle como configuración que use el modelo gpt-4-turbo, al igual que AIDE para tenerlos en igualdad de condiciones en lo que al LLM respecta ya que este no realiza varias iteraciones sobre varios programas buscando cuál es el más óptimo. Este sacará un código, lo ejecutará y nosotros sacaremos el código. \n",
    "\n",
    "Todas las consultas e input+output prompts los podemos encontrar en el fichero pandasai.log. No es recomendable entrar a buscar una consulta simple ya que cada vez que hacemos una llamada a PandasAI este copia input y output en el fichero pandasai.log por lo que es un fichero de tamaño considerable con consultas no parecidas sobre las que pandasai tiene constancia para aumentar la velocidad en las siguientes consultas si estas son monotema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(model=\"gpt-4o\") # Este es el modelo de OpenAI que vamos a utilizar\n",
    "smartDataFrame = SmartDataframe(file, description=DESCRIPTION, config={\"llm\":llm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos el chat y que nos proporcione una solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       698\n",
      "           1       0.99      0.99      0.99       302\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[694   4]\n",
      " [  3 299]]\n"
     ]
    }
   ],
   "source": [
    "response = smartDataFrame.chat(\"Make a classifier for this dataset that predicts if a patient will survive a heart failure? (DEATH_EVENT=1 --> True class)\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Coste de ejecuciónn --> <label style=\"color:red\">Parece que no me ha costado nada</label> < de $.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el código y lo ejecutamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df = dfs[0]\n",
      "X = df.drop('DEATH_EVENT', axis=1)\n",
      "y = df['DEATH_EVENT']\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(X_train, y_train)\n",
      "y_pred = clf.predict(X_test)\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "report = classification_report(y_test, y_pred)\n",
      "conf_matrix = confusion_matrix(y_test, y_pred)\n",
      "result = {'type': 'string', 'value': f\"\"\"Accuracy: {accuracy}\n",
      "\n",
      "Classification Report:\n",
      "{report}\n",
      "\n",
      "Confusion Matrix:\n",
      "{conf_matrix}\"\"\"}\n"
     ]
    }
   ],
   "source": [
    "print(smartDataFrame.last_code_executed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver comparando el código los código de las celdas pegadas a esta no coinciden del todo ya que PandasAI, a diferencia de otras, no devuelve los imports ni printea el resultado ya que este lo devuelve en forma de un report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       698\n",
      "           1       0.98      0.99      0.99       302\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "[[692   6]\n",
      " [  2 300]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "df = file\n",
    "X = df.drop('DEATH_EVENT', axis=1)\n",
    "y = df['DEATH_EVENT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "result = {'type': 'string', 'value': f\"\"\"Accuracy: {accuracy}\n",
    "\n",
    "Classification Report:\n",
    "{report}\n",
    "\n",
    "Confusion Matrix:\n",
    "{conf_matrix}\"\"\"}\n",
    "\n",
    "print(accuracy)\n",
    "print(report)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando el reporte de la clasificación tenemos puntuaciones de accuracy, recall, f1-score y una matriz de confusió casi perfecta por lo que PandasAI ha sido capaz de clasificar perfectamente el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-pandasai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
