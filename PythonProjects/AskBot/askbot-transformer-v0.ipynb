{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASKBOT using Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the continuation of the previous version of ASKBOT using PandasAI but it generated a lot of problems beacuse we can't ask questions with an empty dataframe cause it causes exceeptinos and warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new version of ASKBOT will use pre-trained Transformer models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â PyAudio\n",
    "import pyaudio \n",
    "import wave\n",
    "import audioop\n",
    "import webrtcvad\n",
    "# Speech2Text + Text2Speech\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "# Transformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1 \n",
    "RATE = 16000\n",
    "CHUNK = 320\n",
    "THRESHOLD = 500\n",
    "SILENCE_TIMEOUT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORD AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = pyaudio.PyAudio()\n",
    "stram = audio.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    ")\n",
    "print(\"You can talk now.\\n\\nRecording...\")\n",
    "#\n",
    "frames = []\n",
    "silence_counter = 0\n",
    "vad = webrtcvad.Vad()\n",
    "vad.set_mode(3) # <--- Aggressive detection to record voice\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stram.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        is_speech = vad.is_speech(data, RATE)\n",
    "        if not is_speech:\n",
    "            silence_counter += 1\n",
    "        else:\n",
    "            silence_counter = 0\n",
    "        if silence_counter > int(SILENCE_TIMEOUT * ( RATE / CHUNK ) ):\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Exception catched: {e}\")\n",
    "    \n",
    "print(\"\\nEnd of Recording.\")\n",
    "\n",
    "# Stop stream\n",
    "stram.stop_stream()\n",
    "stram.close()\n",
    "\n",
    "# Stop Pyaudio\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "with wave.open(\"Audios/recorded.wav\", \"wb\") as audio_recorded:\n",
    "    audio_recorded.setnchannels(CHANNELS)\n",
    "    audio_recorded.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    audio_recorded.setframerate(RATE)\n",
    "    audio_recorded.writeframes(b\"\".join(frames))\n",
    "\n",
    "print(\"Audio saved in \\'Audios/\\' as \\'recorded.wav\\'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech2Text <--> Text2Speech functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "def Text2Speech(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    return True\n",
    "\n",
    "def Speech2Text(audioFile):\n",
    "    with sr.AudioFile(audioFile) as audio:\n",
    "        audioFile = r.record(audio)\n",
    "        print(\"Audio loaded.\")\n",
    "        try:\n",
    "            text = r.recognize_google(audioFile, language=\"es-ES\")\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Excepcion catched: {e}\")\n",
    "            return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speech2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Speech2Text(\"Audios/recorded.wav\")\n",
    "type(text) # <--- We check the type of our text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
