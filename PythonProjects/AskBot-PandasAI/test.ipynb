{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Askbot using PandasAI library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motivation of the exercise is to parse the audio from the microphone to text, and and ask to OpenAI model what you said."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote every key i need to use the API's like pandasai or openai into a .env file in my root project directory, if u want to use the app you should make one or copy my method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PandasAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandasai\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm.openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "# # Audio detection\n",
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "import webrtcvad\n",
    "# Speech2Text and Text2Speech\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "# Keys\n",
    "keys = dotenv_values(\"../../.env-token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 320\n",
    "THRESHOLD = 500\n",
    "SILENCE_TIMEOUT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment key\n",
    "os.environ[\"PANDASAI_API_KEY\"] = keys[\"PANDASAI_API_KEY\"]\n",
    "llm = OpenAI(api_token=keys[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can talk now.\n",
      "Recording...\n",
      "\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "# This will record audio till we stay 4 seconds without talk\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "print(\"You can talk now.\\nRecording...\")\n",
    "#\n",
    "frames = []\n",
    "silence_counter = 0\n",
    "vad = webrtcvad.Vad()\n",
    "vad.set_mode(3) #Â <-- Aggressive detection to record voice\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        is_speech = vad.is_speech(data, RATE)\n",
    "        if not is_speech:\n",
    "            silence_counter += 1\n",
    "        else:\n",
    "            silence_counter = 0\n",
    "        if silence_counter >= int( SILENCE_TIMEOUT * ( RATE / CHUNK )):\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(f\"Exception catched: {e}\")\n",
    "\n",
    "print(\"\\nFinished recording.\")\n",
    "\n",
    "# Stop stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "# Stop PyAudio\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded audio as .wav file\n",
    "with wave.open(\"Audios/recorded_audio.wav\", \"wb\") as audio_recorded:\n",
    "    audio_recorded.setnchannels(CHANNELS)\n",
    "    audio_recorded.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    audio_recorded.setframerate(RATE)\n",
    "    audio_recorded.writeframes(b\"\".join(frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we record and saved the audio we still have to process it with speech2text and ask the question to OpenAI.\n",
    "\n",
    "When we complete every step, the we would just have convert to speech the generated text and play it (text2speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech2Text + Text2Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = sr.Recognizer()\n",
    "# This function says everything that is in text variable\n",
    "def Text2Speech(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "def Speech2Text(audioFile):\n",
    "    with sr.AudioFile(audioFile) as audio:\n",
    "        audioFile = r.record(audio)\n",
    "        print(\"Audio loaded\")\n",
    "        try:\n",
    "            text = r.recognize_google(audioFile)\n",
    "            print(text)\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Speech from previus audio into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio loaded\n",
      "hello hello it's me Alex it's taken of me and can you talk to me about these signal processing please\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# speech2text try\n",
    "text = Speech2Text(\"Audios/recorded_audio.wav\")\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ask to a LLE about the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receive the answer and make the lib say it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
