<!doctype html>
<html lang="en"> 
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#F2F0E7";
const accentCol = "#fd4578";

hljs.initHighlightingOnLoad();

const updateTargetDims = () => {
  // width is max-width of `.contentContainer` - its padding
  // return [min(windowWidth, 900 - 80), 700]
  return [windowWidth * (1 / 2), windowHeight];
};

const setCodeAndPlan = (code, plan) => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    // codeElm.innerText = code;
    codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    // planElm.innerText = plan.trim();
    planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
  }
};

windowResized = () => {
  resizeCanvas(...updateTargetDims());
  awaitingPostResizeOps = true;
};

const animEase = (t) => 1 - (1 - Math.min(t, 1.0)) ** 5;

// ---- global constants ----

const globalAnimSpeed = 1.1;
const scaleFactor = 0.57;

// ---- global vars ----

let globalTime = 0;
let manualSelection = false;

let currentElemInd = 0;

let treeStructData = {"edges": [], "layout": [[0.0, 0.0], [0.3333333333333333, 0.0], [0.6666666666666666, 0.0], [1.0, 0.0]], "plan": ["To address the classification task of predicting water potability, I propose\nusing the Gradient Boosting Classifier from the scikit-learn library. This model\nis effective for handling both numerical and categorical data and can manage\nmissing values. First, I'll handle missing values by imputing them using the\nmedian strategy, which is robust against outliers. Next, I'll split the data\ninto training and validation sets to evaluate the model's performance. The\nmodel's effectiveness will be assessed using metrics such as RMSLE, F1-score,\nand accuracy. These metrics will help in understanding the model's prediction\npower and error minimization in terms of logarithmic loss, precision-recall\nbalance, and overall correctness respectively.", "To address the classification of water potability, I will use the Support Vector\nMachine (SVM) classifier with a radial basis function (RBF) kernel as it is\neffective for both linear and non-linear problems. I'll manage missing values by\nimputing them with the median of each feature since this is robust to outliers.\nThe dataset will be split into training and validation sets to train and\nevaluate the model. The performance of the SVM model will be assessed using the\nRoot Mean Squared Logarithmic Error (RMSLE), F1-score, and accuracy, which\nprovide insights into the model's predictive accuracy and error in logarithmic\nscale, along with the balance between precision and recall.", "To tackle the classification of water potability, I will utilize a Logistic\nRegression model due to its simplicity and effectiveness in binary\nclassification tasks. First, I will handle missing data by imputing missing\nvalues using the median for each column. Then, I will normalize the feature\nvalues to ensure that the model trains efficiently. The dataset will be divided\ninto training and validation sets to train and evaluate the model. Performance\nwill be assessed using Root Mean Squared Logarithmic Error (RMSLE), F1-score,\nand accuracy to gauge the model's effectiveness in predicting potability with a\nbalance between error minimization and precision-recall balance.", "To tackle the classification of water potability, I plan to utilize the\nK-Nearest Neighbors (KNN) algorithm, which is straightforward and effective for\nclassification tasks involving multiple features. I will address missing values\nby imputing them with the median of the respective columns, as this is robust\nagainst outliers. The dataset will be split into training and validation sets to\nboth train and evaluate the model's performance. The model's effectiveness will\nbe assessed using Root Mean Squared Logarithic Error (RMSLE), F1-score, and\naccuracy, which provide insights into the model's predictive accuracy and error\nin logarithmic scale, along with the balance between precision and recall."], "code": ["import pandas as pd\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error, f1_score, accuracy_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the data\ndata = pd.read_csv(\"./input/water_potability.csv\")\n\n# Impute missing values\nimputer = SimpleImputer(strategy=\"median\")\ndata_imputed = imputer.fit_transform(data)\ndata = pd.DataFrame(data_imputed, columns=data.columns)\n\n# Split the data into features and target\nX = data.drop(\"Potability\", axis=1)\ny = data[\"Potability\"]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\n\n# Initialize and train the Gradient Boosting Classifier\nmodel = GradientBoostingClassifier(random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# Predict on the validation set\ny_pred = model.predict(X_val_scaled)\n\n# Calculate the evaluation metrics\nrmsle = mean_squared_log_error(y_val, y_pred, squared=False)\nf1 = f1_score(y_val, y_pred)\naccuracy = accuracy_score(y_val, y_pred)\n\n# Print the evaluation metrics\nprint(f\"RMSLE: {rmsle}\")\nprint(f\"F1 Score: {f1}\")\nprint(f\"Accuracy: {accuracy}\")\n", "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import mean_squared_log_error, f1_score, accuracy_score\nfrom sklearn.impute import SimpleImputer\n\n# Load the data\ndata = pd.read_csv(\"./input/water_potability.csv\")\n\n# Impute missing values\nimputer = SimpleImputer(strategy=\"median\")\ndata_imputed = imputer.fit_transform(data)\ndata = pd.DataFrame(data_imputed, columns=data.columns)\n\n# Split data into features and target\nX = data.drop(\"Potability\", axis=1)\ny = data[\"Potability\"]\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\n\n# Initialize and train the SVM classifier\nsvm_model = SVC(kernel=\"rbf\", gamma=\"auto\")\nsvm_model.fit(X_train_scaled, y_train)\n\n# Predict on validation set\ny_pred = svm_model.predict(X_val_scaled)\n\n# Calculate RMSLE, F1-score, and accuracy\nrmsle = np.sqrt(mean_squared_log_error(y_val, y_pred))\nf1 = f1_score(y_val, y_pred)\naccuracy = accuracy_score(y_val, y_pred)\n\n# Print the evaluation metrics\nprint(f\"RMSLE: {rmsle}, F1-score: {f1}, Accuracy: {accuracy}\")\n", "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_log_error, f1_score, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# Load the dataset\ndata = pd.read_csv(\"./input/water_potability.csv\")\n\n# Impute missing values\nimputer = SimpleImputer(strategy=\"median\")\ndata_imputed = imputer.fit_transform(data)\ndata = pd.DataFrame(data_imputed, columns=data.columns)\n\n# Split the data into features and target\nX = data.drop(\"Potability\", axis=1)\ny = data[\"Potability\"]\n\n# Normalize the feature values\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)\n\n# Initialize and train the Logistic Regression model\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n# Predict on validation set\ny_pred = model.predict(X_val)\n\n# Calculate RMSLE, F1-score, and accuracy\nrmsle = mean_squared_log_error(y_val, y_pred, squared=False)\nf1 = f1_score(y_val, y_pred)\naccuracy = accuracy_score(y_val, y_pred)\n\n# Print the evaluation metrics\nprint(f\"RMSLE: {rmsle}\")\nprint(f\"F1-Score: {f1}\")\nprint(f\"Accuracy: {accuracy}\")\n", "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_log_error, accuracy_score, f1_score\nfrom sklearn.impute import SimpleImputer\nfrom numpy import sqrt\n\n# Load the dataset\ndata = pd.read_csv(\"./input/water_potability.csv\")\n\n# Impute missing values with median\nimputer = SimpleImputer(strategy=\"median\")\ndata_imputed = imputer.fit_transform(data)\ndata = pd.DataFrame(data_imputed, columns=data.columns)\n\n# Split the data into features and target variable\nX = data.drop(\"Potability\", axis=1)\ny = data[\"Potability\"]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the K-Nearest Neighbors classifier\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\n# Predict on the validation set\ny_pred = knn.predict(X_val)\n\n# Calculate the RMSLE, F1-score, and accuracy\nrmsle = sqrt(mean_squared_log_error(y_val, y_pred))\nf1 = f1_score(y_val, y_pred, average=\"macro\")\naccuracy = accuracy_score(y_val, y_pred)\n\n# Print the evaluation metrics\nprint(f\"RMSLE: {rmsle}, F1-score: {f1}, Accuracy: {accuracy}\")\n"], "term_out": ["RMSLE: 0.39866068466088184\nF1 Score: 0.3852691218130312\nAccuracy: 0.6692073170731707\nExecution time: 2 seconds seconds (time limit is an hour).", "RMSLE: 0.3855862693033779, F1-score: 0.43454038997214484, Accuracy: 0.6905487804878049\nExecution time: a second seconds (time limit is an hour).", "RMSLE: 0.4227352415462717\nF1-Score: 0.0\nAccuracy: 0.6280487804878049\nExecution time: a moment seconds (time limit is an hour).", "RMSLE: 0.4703022027327424, F1-score: 0.47251717343841526, Accuracy: 0.5396341463414634\nExecution time: a second seconds (time limit is an hour)."], "analysis": ["The Gradient Boosting Classifier model was able to achieve an RMSLE of 0.3987, an F1 score of 0.3853, and an accuracy of 66.92% on the validation set. These metrics indicate a moderate performance of the model, with a relatively lower F1 score suggesting room for improvement in balancing precision and recall.", "The SVM classifier model was successfully trained and evaluated on the water potability dataset. The model achieved an RMSLE of 0.3856, an F1-score of 0.4345, and an accuracy of 69.05%. These metrics indicate the model's performance in predicting water potability, with a moderate degree of accuracy and a relatively low error in logarithmic scale.", "The Logistic Regression model produced an RMSLE of 0.4227, an F1-score of 0.0, and an accuracy of 0.6280 on the validation set. The F1-score of 0.0 suggests that the model failed to correctly predict positive class instances (potable water), which indicates poor model performance for classifying potable instances. This could be due to class imbalance or model's inability to capture the underlying patterns effectively.", "The K-Nearest Neighbors classifier was used to predict water potability. The evaluation metrics reported are RMSLE: 0.4703, F1-score: 0.4725, and Accuracy: 0.5396. These metrics suggest that the model's performance is moderate, with an accuracy slightly above 50%, indicating room for improvement."], "exp_name": "0-space-badger-of-infinity", "metrics": [0, 0, 0, 0]}

let lastClick = 0;
let firstFrameTime = undefined;

let nodes = [];
let edges = [];

let lastScrollPos = 0;

setup = () => {
  canvas = createCanvas(...updateTargetDims());
};

class Node {
  x;
  y;
  size;
  xT;
  yT;
  xB;
  yB;
  treeInd;
  color;
  relSize;
  animationStart = Number.MAX_VALUE;
  animationProgress = 0;
  isStatic = false;
  hasChildren = false;
  isRootNode = true;
  isStarred = false;
  selected = false;
  renderSize = 10;
  edges = [];
  bgCol;

  constructor(x, y, relSize, treeInd) {
    const minSize = 35;
    const maxSize = 60;

    const maxColor = 10;
    const minColor = 125;

    this.relSize = relSize;
    this.treeInd = treeInd;
    this.size = minSize + (maxSize - minSize) * relSize;
    this.color = minColor + (maxColor - minColor) * relSize;
    this.bgCol = Math.round(Math.max(this.color / 2, 0));

    this.x = x;
    this.y = y;
    this.xT = x;
    this.yT = y - this.size / 2;
    this.xB = x;
    this.yB = y + this.size / 2;

    nodes.push(this);
  }

  startAnimation = (offset = 0) => {
    if (this.animationStart == Number.MAX_VALUE)
      this.animationStart = globalTime + offset;
  };

  child = (node) => {
    let edge = new Edge(this, node);
    this.edges.push(edge);
    edges.push(edge);
    this.hasChildren = true;
    node.isRootNode = false;
    return node;
  };

  render = () => {
    if (globalTime - this.animationStart < 0) return;

    const mouseXlocalCoords = (mouseX - width / 2) / scaleFactor;
    const mouseYlocalCoords = (mouseY - height / 2) / scaleFactor;
    const isMouseOver =
      dist(mouseXlocalCoords, mouseYlocalCoords, this.x, this.y) <
      this.renderSize / 1.5;
    if (isMouseOver) cursor(HAND);
    if (isMouseOver && mouseIsPressed) {
      nodes.forEach((n) => (n.selected = false));
      this.selected = true;
      setCodeAndPlan(
        treeStructData.code[this.treeInd],
        treeStructData.plan[this.treeInd],
      );
      manualSelection = true;
    }

    this.renderSize = this.size;
    if (!this.isStatic) {
      this.animationProgress = animEase(
        (globalTime - this.animationStart) / 1000,
      );
      if (this.animationProgress >= 1) {
        this.isStatic = true;
      } else {
        this.renderSize =
          this.size *
          (0.8 +
            0.2 *
              (-3.33 * this.animationProgress ** 2 +
                4.33 * this.animationProgress));
      }
    }

    fill(this.color);
    if (this.selected) {
      fill(accentCol);
    }

    noStroke();
    square(
      this.x - this.renderSize / 2,
      this.y - this.renderSize / 2,
      this.renderSize,
      10,
    );

    noStroke();
    textAlign(CENTER, CENTER);
    textSize(this.renderSize / 2);
    fill(255);
    // fill(lerpColor(color(accentCol), color(255), this.animationProgress))
    text("{ }", this.x, this.y - 1);
    // DEBUG PRINT:
    // text(round(this.relSize, 2), this.x, this.y - 1)
    // text(this.treeInd, this.x, this.y + 15)

    const dotAnimThreshold = 0.85;
    if (this.isStarred && this.animationProgress >= dotAnimThreshold) {
      let dotAnimProgress =
        (this.animationProgress - dotAnimThreshold) / (1 - dotAnimThreshold);
      textSize(
        ((-3.33 * dotAnimProgress ** 2 + 4.33 * dotAnimProgress) *
          this.renderSize) /
          2,
      );
      if (this.selected) {
        fill(0);
        stroke(0);
      } else {
        fill(accentCol);
        stroke(accentCol);
      }
      strokeWeight((-(dotAnimProgress ** 2) + dotAnimProgress) * 2);
      text("*", this.x + 20, this.y - 11);
      noStroke();
    }

    if (!this.isStatic) {
      fill(bgCol);
      const progressAnimBaseSize = this.renderSize + 5;
      rect(
        this.x - progressAnimBaseSize / 2,
        this.y -
          progressAnimBaseSize / 2 +
          progressAnimBaseSize * this.animationProgress,
        progressAnimBaseSize,
        progressAnimBaseSize * (1 - this.animationProgress),
      );
    }
    if (this.animationProgress >= 0.9) {
      this.edges
        .sort((a, b) => a.color() - b.color())
        .forEach((e, i) => {
          e.startAnimation((i / this.edges.length) ** 2 * 1000);
        });
    }
  };
}

class Edge {
  nodeT;
  nodeB;
  animX = 0;
  animY = 0;
  animationStart = Number.MAX_VALUE;
  animationProgress = 0;
  isStatic = false;
  weight = 0;

  constructor(nodeT, nodeB) {
    this.nodeT = nodeT;
    this.nodeB = nodeB;
    this.weight = 2 + nodeB.relSize * 1;
  }

  color = () => this.nodeB.color;

  startAnimation = (offset = 0) => {
    if (this.animationStart == Number.MAX_VALUE)
      this.animationStart = globalTime + offset;
  };

  render = () => {
    if (globalTime - this.animationStart < 0) return;

    if (!this.isStatic) {
      this.animationProgress = animEase(
        (globalTime - this.animationStart) / 1000,
      );
      if (this.animationProgress >= 1) {
        this.isStatic = true;
        this.animX = this.nodeB.xT;
        this.animY = this.nodeB.yT;
      } else {
        this.animX = bezierPoint(
          this.nodeT.xB,
          this.nodeT.xB,
          this.nodeB.xT,
          this.nodeB.xT,
          this.animationProgress,
        );

        this.animY = bezierPoint(
          this.nodeT.yB,
          (this.nodeT.yB + this.nodeB.yT) / 2,
          (this.nodeT.yB + this.nodeB.yT) / 2,
          this.nodeB.yT,
          this.animationProgress,
        );
      }
    }
    if (this.animationProgress >= 0.97) {
      this.nodeB.startAnimation();
    }

    strokeWeight(this.weight);
    noFill();
    stroke(
      lerpColor(color(bgCol), color(accentCol), this.nodeB.relSize * 1 + 0.7),
    );
    bezier(
      this.nodeT.xB,
      this.nodeT.yB,
      this.nodeT.xB,
      (this.nodeT.yB + this.nodeB.yT) / 2,
      this.animX,
      (this.nodeT.yB + this.nodeB.yT) / 2,
      this.animX,
      this.animY,
    );
  };
}

draw = () => {
  cursor(ARROW);
  frameRate(120);
  if (!firstFrameTime && frameCount <= 1) {
    firstFrameTime = millis();
  }
  // ---- update global animation state ----
  const initialSpeedScalingEaseIO =
    (cos(min((millis() - firstFrameTime) / 8000, 1.0) * PI) + 1) / 2;
  const initialSpeedScalingEase =
    (cos(min((millis() - firstFrameTime) / 8000, 1.0) ** (1 / 2) * PI) + 1) / 2;
  const initAnimationSpeedFactor = 1.0 - 0.4 * initialSpeedScalingEaseIO;
  // update global scaling-aware clock
  globalTime += globalAnimSpeed * initAnimationSpeedFactor * deltaTime;

  if (nodes.length == 0) {
    const spacingHeight = height * 1.3;
    const spacingWidth = width * 1.3;
    treeStructData.layout.forEach((lay, index) => {
      new Node(
        spacingWidth * lay[0] - spacingWidth / 2,
        20 + spacingHeight * lay[1] - spacingHeight / 2,
        1 - treeStructData.metrics[index],
        index,
      );
    });
    treeStructData.edges.forEach((ind) => {
      nodes[ind[0]].child(nodes[ind[1]]);
    });
    nodes.forEach((n) => {
      if (n.isRootNode) n.startAnimation();
    });
    nodes[0].selected = true;
    setCodeAndPlan(
      treeStructData.code[0],
      treeStructData.plan[0],
    )
  }

  const staticNodes = nodes.filter(
    (n) => n.isStatic || n.animationProgress >= 0.7,
  );
  if (staticNodes.length > 0) {
    const largestNode = staticNodes.reduce((prev, current) =>
      prev.relSize > current.relSize ? prev : current,
    );
    if (!manualSelection) {
      if (!largestNode.selected) {
        setCodeAndPlan(
          treeStructData.code[largestNode.treeInd],
          treeStructData.plan[largestNode.treeInd],
        );
      }
      staticNodes.forEach((node) => {
        node.selected = node === largestNode;
      });
    }
  }
  background(bgCol);
  // global animation transforms
  translate(width / 2, height / 2);
  scale(scaleFactor);

  
  // ---- fg render ----
  edges.forEach((e) => e.render());
  nodes.forEach((n) => n.render());
  
};

    </script>
    <title>AIDE Run Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
        overflow: scroll;
      }
      body {
        background-color: #f2f0e7;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 40vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
    </style>
  </head>
  <body>
    <pre
      id="text-container"
    ><div id="plan"></div><hr><code id="code" class="language-python"></code></pre>
  </body>
</html>
